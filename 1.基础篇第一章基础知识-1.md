### 基 础 篇
- 第1章 大语言模型的基础知识
- 第2章 大语言模型应用架构
- 第3章 大语言模型应用的工作模式

大语言模型是自然语言处理的一个重要分支。近几年来，随着Transformer架构和自注意力机制的引入，大语言模型得到了广泛应用，尤其在生成式人工智能领域取得了长足的发展。直接学习如何操作大语言模型虽然可以让读者掌握一些技能，但读者常常知其然而不知其所以然，一旦应用场景稍有变化，就会产生困惑。而掌握一定的大语言模型基础知识，可以为操作和应用开发进行重要的铺垫，帮助读者在操作大模型和开发应用时，更深入地理解执行步骤或源代码的原理。

本篇分为3章，讲解大语言模型的基础知识、应用架构、应用工作模式。
- 第1章介绍大语言模型的发展历程、基本原理、应用开发技术和常用训练方法，重点讲解了Transformer架构和自注意力机制。
- 第2章介绍大语言模型应用涉及的软硬件在整体架构中的作用，为后续部署和开发奠定基础。 
- 第3章介绍应用开发中服务端的工作模式和流程，前端与后端的交互方法，以及客户端开发常用的技术。

### 第1章 大语言模型的基础知识
随着ChatGPT在全球范围内的普及，生成式人工智能已经成为人们日常生活中不可或缺的一部分。AIGC（Artificial Intelligence Generated Content，人工智能生成内容）因其独特的创造力而备受瞩目，用户只需提供提示词，背后的人工智能服务便能够生成符合用户需求的文本、图像、音频和视频等多样化内容。这种技术正在以前所未有的方式改变着我们的生产和生活。

大语言模型（或称“大模型”）是指能够处理和生成自然语言文本的、参数规模很大的人工智能模型。这种模型基于深度学习技术并经过海量语料训练，利用大量的计算资源来学习大规模文本数据的统计规律，以捕捉自然语言的语法、语义和上下文信息。大语言模型被广泛应用于文本生成、机器翻译、对话系统等自然语言处理场景中，正在不断推动这些领域的发展和创新。

GPT（Generative Pre - Trained Transformer，生成式预训练Transformer ）是大语言模型的一种具体实现，由OpenAI提出，基于Transformer架构，采用了自注意力机制和多头注意力机制，可有效地处理长距离依赖关系和上下文信息。Transformer架构是目前大语言模型的主要技术体系，自2017年由Google的翻译团队提出后迅速流行开来，促进了大语言模型的快速发展。基于Transformer架构涌现出很多模型，如OpenAI的GPT - 3.5、GPT - 4，Anthropic的Claude3，以及Meta开源的LLaMA2等，其中也有一些优秀的开源国产模型，如智谱华章ChatGLM、通义千问、百川等，用户可以下载并免费使用这些模型。

本章介绍大语言模型的基本概念、基本原理、应用开发技术和训练方法，以便读者全面了解大语言模型的基础知识。

Transformer的原意是变形金刚或变压器，在人工智能领域中代表一种转变，如将一种语言翻译成另一种。

#### 1.1大语言模型概述
##### 1.1.1基本情况
自然语言处理是研究如何利用机器来处理和理解人类语言的理论及技术领域。作为人工智能的一个重要分支和计算语言学的子领域，自然语言处理的目标是使机器真正理解人类语言，解决在计算机处理过程中出现的各种语言相关问题，实现人机交互，并以人类可以理解的方式进行反馈。自然语言处理涉及多个研究方向，包括语音识别、自然语言理解、对话系统、机器翻译等。近年来，随着深度学习在自然语言处理领域的广泛应用，该领域取得了巨大的进展。

大语言模型是自然语言处理的一种技术方向。与传统的专用“小”模型不同，大语言模型凭借“大”语料、“大”算力和“大”参数取得优势。当规模达到一定程度时，模型会展现出涌现能力（Emergent Ability），即从原始训练数据中自动学习并发现新的、更高层次的特征和模式的能力。简而言之，大语言模型具有触类旁通的能力，其知识不仅来源于原始语料，还能够创造性地生成，这是小模型难以达到的。

大语言模型在自然语言处理领域具有广泛的应用，涵盖了许多子领域。以下是大语言模型的一些应用场景。

1. **自然语言生成**：模型的自然语言生成能力使其成为生成文章、源程序、故事、新闻报道、营销文案等文本内容的理想工具。这些生成的文本通常都是合理、流畅并且符合语法规则的。

2. **自动问答系统**：回答用户提出的问题，如智能客服、知识库增强检索等。这类系统可以暂存用户的问答历史记录，进行多轮关联问答对话。 

3. **对话系统**：以Chat方式与用户进行交流，如智能助手、聊天机器人等。这类系统可以根据用户的提问或指令生成语义正确、语气自然、逻辑合理的回答或响应。 

4. **文本摘要**：提取文本中的关键信息，生成摘要或总结，如论文的摘要书写、医疗文书的结构化信息生成等。 

5. **机器翻译**：利用大语言模型的上下文理解能力、长距离依赖建模和多语言支持等特性，改进语言翻译效果。 

6. **代码生成**：生成代码片段或程序代码，如自动化编程、代码补全等。

##### 1.1.2发展历史
大语言模型的起源可以追溯到早期的自然语言处理研究，包括基于规则的方法和基于统计的方法。基于规则的方法由于灵活性不足，发展缓慢；而基于统计的方法从20世纪90年代至今，取得了长足的发展。通过学习大量来自互联网的语料取得“经验”、提升能力，大语言模型在翻译领域的应用非常成功，其主流的技术是卷积神经网络（CNN）、循环神经网络（RNN）以及Word2Vec词嵌入技术等。 

大语言模型的突破性发展出现在2017年，随着Google机器翻译团队那篇著名的论文“Attention is All You Need” 的发表，采用注意力（Attention）机制的Transformer架构开始大行其道。2018年OpenAI推出了GPT系列模型，包括GPT - 1和GPT - 2，这些模型都使用了Transformer架构，并收集了大量的语料库进行训练，从而实现了对长序列文本的处理和生成。 

OpenAI的GPT - 2可称得上是一个划时代的模型。以现在的技术来看，GPT - 2参数量较少，基本上用于推理和文本补全场合，其知名度与GPT - 4相去甚远。但实际上它已基本上具备了大语言模型在训练、语义理解、推理生成等方面的大部分特性，这几年在文本生成和分析场景中的应用非常广泛。 

随着模型开发技术的进步、算力的提升，大语言模型的参数规模也在不断地扩大。2020年，OpenAI推出了GPT - 3，该模型拥有1750亿个参数。基于GPT - 3的现象级应用是OpenAI和GitHub联合推出的Copilot辅助代码补全工具。同期，Google推出了BERT模型，它使用双向Transformer架构，在多个NLP任务中取得了显著成果。 

在基于GPT - 3.5的ChatGPT面世之前，大语言模型虽然发展迅速，但依然是应用在比较专业的领域，如机器翻译、代码书写、文本推理生成等。直到2022年11月OpenAI发布了ChatGPT，大语言模型从推理、预测这些相对专业的技术应用转变为人性化的聊天应用，进入大众的日常生活。之后，同类大模型层出不穷，国产模型也不断涌现，形成“百模大战”的态势。 

大语言模型的技术方向和发展历程由Mooler0410整理，在https://github.com/Mooler0410/LLMsPracticalGuide上可以查阅，进化树见图1 - 1。 

1. **从发布年份来看**（下面对年份进行了夸张描述，实际上只有短短6年的时间），主要的大语言模型如下。
    - “史前”：Word2Vec。
    - “远古”：BERT、GPT - 1。 
    - “近古”：GPT - 2、XLNet。 
    - “近代”：GPT - 3、T5、GLM。 
    - “现代”：GPT - 4、LLaMA2、Gemma、Claude3。 

2. **从厂商来看**，主要的大语言模型如下。
    - Google：BERT、T5、Gemma。 
    - OpenAI：GPT - 2、GPT - 3、GPT - 4。 
    - Claude：Claude2、Claude3。 
    - Meta (Facebook)：LLaMA2。 
    - 国产：GLM 

3. **从架构来看**（Encoder和Decoder是Transformer的组成部分），主要的大语言模型如下。
    - Encoder - only（仅编码器）：BERT。 
    - Encoder - Decoder（编码器 - 解码器）：GLM、T5。 
    - Decoder - only（仅解码器）：GPT、LLaMA、Claude、Gemma。 

https://arxiv.org/abs/1706.03762。

#### 1.1.3发展现状
大语言模型处于高速发展阶段，但依然处于OpenAI的GPT系列一骑绝尘、其他公司努力追赶的态势。Anthropic推出了Claude3，可能对GPT的地位构成一定威胁。Meta的LLaMA出现ChatGPT之后，但其开源生态对业界的推动非常大，涌现出一批基于LLaMA架构的国内外开源模型，满足了使用者在文本方面的大部分需求。Google的Gemma推出时间不长，但起点比较高。国内的模型除商业运转的文心一言、讯飞星火外，还有一些开源的模型，如ChatGLM、阿里通义千问等，为用户提供了更多选择。整体而言，大语言模型领域的竞争日益激烈，各家厂商都在不断努力创新，为用户带来更优质的文本处理体验。

除了模型厂家推出的Chat类应用外，对开源大语言模型进行微调并将其应用于垂直专业领域也是大语言模型应用的重要发展方向。金融、医疗、编程等领域的专用大模型正在迅速发展。类似的定制化模型在不同行业中发挥着越来越重要的作用，为专业领域的用户提供了更加精准、高效的文本处理和分析工具。随着这些应用的不断完善和普及，开源大语言模型在专业垂直领域的应用前景将会更加广阔，为各行各业带来更多创新和便利。

从技术方面看，基于Transformer的Decoder - only架构是大语言模型的主流，各种模型表现出一定的技术趋同性。大部分开源的大模型都托管到huggingface.co网站，用户可以使用Hugging Face的Transformers库 （Package ）进行装载、推理、微调等。

Hugging Face的Transformers库是基于PyTorch和TensorFlow构建的自然语言处理工具库，用于训练和使用预训练的NLP模型，以完成各种基于Transformer模型的自然语言处理任务，如文本分类、命名实体识别、文本生成等。

Package，原义是“包”，本书统一使用“库”以便说明其功能。

![image](https://github.com/user-attachments/assets/8e93efd4-8af5-4e15-8a31-9e99aa9cd66f)



#### 1.1.4发展趋势
首先，大语言模型在文本方面的能力已相当成熟，即使是具有2B（20亿）参数规模的较小模型，在大部分日常与文本相关的生产生活场景中，也表现得比较出色。其次，在多模态领域，大语言模型在理解图像、生成图像方面也逐渐走向成熟，文本生成图像（文生图）和图像生成图像（图生图）的应用越来越完善。另外，近期OpenAI发布的人工智能文生视频模型Sora代表着一个全新的方向，开辟了多模态智能应用的新的可能性。

模型的小型化是另一个重要的应用发展趋势。大语言模型是将自然语言问题转化为数字计算的应用，因此GPU算力是大模型的主要运行资源。在实践中，对数值的计算可以容忍一定的精度下降而对结果无显著影响，基于这一前提，发展出了大语言模型的量化应用，即将模型中的权重（Weight）从高精度格式转换成低精度格式，如将32位浮点数转换成8位整数INT8的格式，期望量化后的模型在准确率上与量化前相近。经过量化处理的模型，可以脱离GPU而被移植到CPU上运行，甚至可以部署在Android手机上运行。这样的端侧部署方案在一些安全性要求高的环境、垂直专业领域、离线应用场景有一定的发展潜力。

### 1.2基本原理
大语言模型首先在大规模的无标注语料上进行自监督预训练，通过掩码语言模型、下一句预测等任务，学习语言统计规律，之后针对下游NLP任务进行微调，以适应特定任务。例如，将基础模型微调后得到Chat模型，以便模型在对话任务中工作得更好。这种无标注语料的方法减少了模型对大量标注数据的依赖，使其可进行自回归生成，逐词预测下一个最可能的token 。 

在文本生成过程中，模型学习如何连贯、流畅地产生由token组成的语言序列。这种生成机制模拟了人类语言的产生过程。大语言模型的参数量通常在十亿级甚至千亿级，这使其可以学习大量的语言知识，拟合训练语料的分布，理解语义信息，显示出强大的语言生成能力。

token是指文本中最小的语义单元，可以是单词、字、字符或标点。

#### 1.2.1Transformer架构
大语言模型通常采用Transformer或其优化版本作为骨干架构。Transformer是一种基于自注意力（Self - attention）机制的深度学习模型架构，由Google翻译团队的Ashish Vaswani等人在2017年提出，主要用于处理序列数据。而在自然语言处理任务中，文本序列经过词汇表索引等方式转换为数字序列的形式，这一步骤是将语言处理转化为数学计算的关键环节。

Transformer的核心是自注意力机制，能够在一个文本序列中的不同位置之间建立关联，从而更好地捕捉序列中的长距离依赖关系。通过自注意力机制，Transformer能够并行处理输入序列中的不同位置信息，使其在处理长序列时具有更好的性能。在Transformer中，输入序列经过多层的注意力机制和前馈神经网络处理，最终输出表示序列的向量。基于Transformer的模型结构包括Encoder（编码器）和Decoder（解码器）两部分，Encoder用于将输入序列编码为隐藏表示，Decoder则用于根据Encoder的输出生成目标序列。Transformer能够通过编码器 - 解码器结构、多头自注意力机制以及前馈全连接神经网络，学习语言中的长距离依赖关系，理解语义信息。由于Transformer具有并行计算能力和良好的建模能力，它在机器翻译、文本生成和问答系统等任务中表现出色。其架构如图1 - 2所示。 

![image](https://github.com/user-attachments/assets/984936b2-13d9-4d86-af7b-eeefbd01e6dc)



**图1 - 2 Transformer架构示意**

输入：我是一个学生

Transformer

输出：I am a student

#### 1.2.2编码器与解码器
在Transformer中，输入序列首先通过一个编码器进行编码，然后通过一个解码器进行解码，最终输出目标序列。编码器和解码器并不总是成对出现，在近几年的发展中，大语言模型对Transformer架构的使用分化为三个技术流派：Encoder - only、Encoder - Decoder和Decoder - only。目前来看，Decoder - only方向是主流。

Transformer的编码器和解码器由多个相同的层堆叠而成。每个层包含两个子层：多头自注意力机制（Multi - Head Self - Attention）层和前馈全连接神经网络（Feed - Forward Fully Connected Neural Network）层。在每个子层之间还加入了残差连接和层归一化操作，有助于缓解梯度消失问题，加速训练过程。

Transformer由6层编码器和6层解码器组成，每一层编码器的输入是前一层编码器的输出，而每一层解码器的输入不仅是其前一层解码器的输出，还包括了整个编码部分的输出。原始的文字通过编码和解码过程，最终形成目标文本。其结构如图1 - 3所示。 

![image](https://github.com/user-attachments/assets/caef74fb-debf-4955-8ced-bb5f257fb9a8)


**图1 - 3 Transformer分层结构**

输入：我是一个学生

Encoder（6层）

Decoder（6层）

输出：I am a student


#### 1.2.3自注意力机制

自注意力机制是一种用于计算序列数据中不同位置之间依赖关系的方法。在自注意力机制中，每个输入位置都会与其他位置进行交互，以便根据它们之间的关系来调整其表示。自注意力机制允许模型查看输入序列中的其他token，以便更好地理解序列中的某个token。



如图1 - 4所示，在“大”“模”“型”三个token之间，“型”与“大”的关系最密切，与“模”的关系次之。


![image](https://github.com/user-attachments/assets/d6e97a25-b453-433c-aa01-ce26a9b567c5)


**图1 - 4 自注意力机制示意**

大 - 大

模 - 模

型 - 型

注意力函数用于计算输入序列中每个位置与其他位置之间的注意力权重，可以描述为将一个查询和一组键值对映射到输出，其中查询（Q）、键（K）、值（V）和输出都是向量，输入乘以三个不同的权重矩阵分别得到Q、K、V，如图1 - 5所示。


**图1 - 5 自注意力中的Q、K、V**

大模型 × $W^Q$ = Q（大模型）

大模型 × $W^K$ = K（大模型）

大模型 × $W^V$ = V（大模型）

![image](https://github.com/user-attachments/assets/32a273d7-e399-4140-83c1-5fd04495722e)


Q乘以$K^T$得到一个3×3矩阵，分别表示一个token内各元素之间的注意力值（相关性），见图1 - 6。

![image](https://github.com/user-attachments/assets/1e762a54-b0a8-40a0-8812-bf20b30f18a3)



**图1 - 6 注意力计算过程示意**

大模型 × $K^T$ = $\begin{bmatrix}0.8 & 0.2 & 0.1 \\ 0.4 & 0.5 & 0.3 \\ 0.3 & 0.2 & 0.8\end{bmatrix}$

“大”和“大”的注意力 = 0.8

“大”和“模”的注意力 = 0.2

“大”和“

![image](https://github.com/user-attachments/assets/41dc13a9-353c-4c3b-a47b-c0074093b616)

![image](https://github.com/user-attachments/assets/37acb019-699d-4e78-9c75-004073537b8e)


