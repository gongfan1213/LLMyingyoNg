### Preface前言
大语言模型（Large Language Model, LLM）是自然语言处理（Natural Language Processing, NLP）中的一个重要分支，它基于深度学习，采用海量文本数据和大量算力进行训练。训练后的模型能够理解和生成人类语言文本，执行与语言文本相关的任务，包括文本生成、代码补全、文章总结、翻译和情感分析等。

经过多年的发展，NLP技术在与人类语言相关的领域有着较为广泛的应用，如自动翻译、智能语音客服、文稿校对、语音助手等。这些应用场景通常涉及相对专业的需求。然而，随着ChatGPT的流行，大语言模型开始从专业领域走进大众的生活。以聊天（Chat）方式回答人们提出的问题，这种交互方式在日常生活中司空见惯，但出现在人工智能领域却非常新颖。这种趋势促使ChatGPT及类似产品迅速得到普及和应用，其背后的原理、训练过程等也逐步引起人们的关注。

大语言模型的应用非常广泛。例如，在辅助编程中，大语言模型能够根据上下文提示补全代码或编写整个函数；在智能语音客服中，大语言模型可以基于自然语言对用户提出的问题进行理解，并给出相应的答案；在教育领域，大语言模型可以帮助学生更好地理解和掌握知识，提高学习效率；在翻译领域，大语言模型能够准确地理解语言的语境、含义和结构，使翻译更加准确；大语言模型可以与语音、图像、视频等融合，形成多模态应用，如智能语音机器人、数字人等；大语言模型还可以与开发活动进行整合，产生如人工智能代理（AI Agent）等创新应用。

### 本书特点
这是一本介绍大语言模型基础知识、操作方法和应用开发的书。本书内容来源丰富且可靠，我在写作过程中抱持谨慎态度，确保读者能从中获得准确的信息。具体而言，本书的材料来源主要包括以下几个方面。
- 培训课件：在过去两年中，我作为讲师，面向教师、学生以及软件企业举办了多场大语言模型培训，深入了解了用户的实际需求。
- 社交媒体互动：我将自己在知乎等平台上发布的文章进行了整理和细化，这些文章曾引起读者的广泛关注。
- 实践案例：在本书撰写过程中，我开发了一系列示例程序，并对实际操作步骤进行了验证和测试。
- 开源项目：我将自己在GitHub平台上发布的开源应用进行了必要的调整和改进，以适应书中的说明和示例。
- 官方资源：我整合了来自各个大语言模型官网的资料，确保提供权威和最新的信息。

### 读者对象
本书涉及的模型丰富、操作步骤详细、源代码完整，便于大模型应用的使用者和开发者阅读及实践。
- 对于使用者来说，本书能满足其在部署、微调方面的需求。
- 对于开发者来说，9个不同领域的开发案例能满足其学习、实践的需求。

### 如何阅读本书
本书面向大语言模型应用的使用者和开发者，从大语言模型的基础知识开始，逐步深入，详细介绍了常见的操作方法和各类型应用的开发过程。
全书共18章，分为三篇。
- 基础篇（第1～3章），讲解大语言模型的基础知识、应用架构、应用工作模式。
- 操作篇（第4～8章），讲解大模型的实操环节，包括应用环境的搭建，多种大模型的安装、微调与量化等，囊括了大模型的常用操作。 
- 开发篇（第9～18章），详细讲述大语言模型在9个领域的应用开发过程，包括Chat、编程、RAG、翻译、AI Agent、语音、数字人、提示词生成、AI小镇等，涵盖应用的开发目标、原理及开发过程，中间还穿插讲解了VS Code插件的开发，丰富了应用的运行场景。具体来说，本篇中每章都阐述了示例的设计目标，详细介绍了应用的运行原理，给出了源代码、运行方法、运行结果，内容完整，各章自成体系，章与章之间无严格的阅读顺序。

### 勘误和支持
虽然我在写作时已经尽力谨慎，但本书中仍可能出现一些错误或者不准确的地方，恳请读者指正。若读者发现有错漏之处或者提出宝贵意见，请通过邮箱little51@126.com联系我。
本书的所有源代码和简要操作步骤，都在https://github.com/little51/llm-dev上开源，读者可自行查阅。

### 实践要求及说明
在本书的所有示例中，涉及GPU的项目均可在16GB内存的推理卡或显卡上实现。虽然有一部分示例只需要8GB或6GB内存即可实现，但为了完整实践所有示例，还是建议采用16GB或16GB以上内存的推理卡或显卡，以及与之配套的服务器或高性能的个人计算机（PC）。

以下是关于代码的注意事项。
①由于排版中对每行代码长度的限制，Python程序中一些长行用反斜杠“\”强制换行，这也是符合Python语法规范的。
②在操作系统命令行下执行命令时，Linux支持对较长的命令采用反斜杠“\”进行换行，命令执行结果不会发生变化。在Windows系统中此方法不适用。如果遇到使用“\”且换行的命令要在Windows上执行，则需要将“\”去掉且不能换行。
例如，以下命令在Linux系统中运行正常。
```
pip install -r requirements.txt -i \
https://pypi.mirrors.ustc.edu.cn/simple
```
而如果要在Windows系统上运行，则需要把行尾的“\”删去，并且不换行，保持命令为一行。
```
pip install -r requirements.txt -i https://pypi.mirrors.ustc.edu.cn/simple
```
③本书中描述的在操作系统命令行环境下执行的命令，如果以“#”开头则为注释，无须执行。 
④本书的大部分内容在Linux和Windows上均可实践，对于只能在Windows或只能在Linux下操作及运行的内容，书中会进行特别强调。 
⑤得益于Python语言的精练以及Transformers、PyTorch等库的封装，本书的示例代码大多在100行以内。如未特殊说明，则书中列出的是完整源代码。 
⑥为了统一和规范书中的IP地址使用格式，以减少歧义，本书采用以下约定：如果是本机地址，则使用127.0.1表示；如果涉及运行大语言模型的服务器，则使用主机名“server-llm-dev”指代。这个主机名具体是指定专用服务器还是本机，则通过配置DNS解析来确定：在Windows系统中，修改C:\Windows\System32\drivers\etc\HOSTS文件；在Linux系统中，修改/etc/hosts文件。

### 致谢
2022年年底，我开始进行大语言模型应用相关的研发工作，涉及各种大模型的部署、微调和应用开发。在实践中，我将一些操作步骤和心得体会分享到知乎等社交媒体，与网友进行了很多良好的互动。随着大语言模型的普及，各行业对这一领域的关注度在不断上升，我也有机会承担一些与大语言模型相关的培训和讲座工作。在制作课件的过程中，为了方便学员实践，我梳理了大语言模型的相关知识，尽量详细地描述实践过程，这中间积累了本书的一些原始素材。2024年年初，经过积累与筹备，我开始正式撰写这本关于大语言模型操作与应用开发的图书。经过近三个月的程序调试和文本写作，本书终于成型。

首先，感谢我所在公司的集团领导梁明道先生。他对软件技术的发展具有远见卓识，特别是对开源社区和人工智能领域具有独到见解。三年前，他就安排采购了一批高性能推理卡，这些设备支撑了我的研发工作和本书涉及的代码调试的基础算力。

感谢我的同事董炜。他事无巨细地组织了历次培训工作，使我能够集中精力备课和授课，同时能够持续跟进大语言模型的最新发展。这些培训经验为本书提供了重要的写作素材。

感谢我的同事杨乐。他对大语言模型充满热情。他看到本书的初稿时，帮助我联系了出版社。没有他的鼓励和协调，本书可能不会这么顺利问世。

感谢我的妻子刘莉博士。在本书写作的过程中，她提出了许多宝贵的建议，比如如何行文能让读者更易于阅读和理解。

最后，感谢我的儿子高唯之小朋友。他在Python课程方面取得了很好的成绩，正在学习人工智能编程，他在编程方面的热情激励着我持续写作。 
