### 第8章 Chapter 8 多模态模型应用

多模态模型应用是一种先进的深度学习技术。它能对文本、图像、音频和视频等进行整合，学习不同模态之间的关联，实现文本、音频、视频之间的相互转换和生成。

图像生成是多模态模型的一个具体应用方向，是指使用AI算法生成图像的过程，这些图像包括照片、绘画、3D渲染或者是创意图像。在图像生成技术的文生图（Text - to - Image）和图生文（Image - to - Text）领域都出现了大量成熟的产品，如文生图的DALL - E2、Stable Diffusion和图生文的Flamingo等。


本章介绍Stable Diffusion的使用方法，包括安装部署过程、文生图和图生文等功能的操作步骤等。通过阅读本章，读者可以初步了解Stable Diffusion的基本概念和使用方法，为数字人制作做好技术准备。



#### 8.1 Stable Diffusion介绍

Stable Diffusion是Stability AI开发的一种开源AI绘画工具，于2023年6月发布。它基于深度学习技术实现，用于根据文本的描述生成精细图像。通过给定的文本提示词，Stable Diffusion模型会输出一张匹配提示词的图像。而这种由文本提示词到图像生成的过程被称为“文生图”。

Stable Diffusion还可以实现图像反推的功能，即输入一张图片，Stable Diffusion会对其进行深入分析，提取出图像中关键信息，转化为一段描述该图的文字。这个过程被称为“图生文”。在此基础上，按这段文字再生成新的图像，就实现了“图生图”的过程。

至于Stable Diffusion的核心运行原理，则是将输入的噪声图像转换为目标图像。这分为前向扩散和稳定化两个关键步骤。

- **前向扩散**：利用逐步引入高斯噪声的方式，模拟图像向随机状态演变的过程，将输入的噪声图像与随机噪声混合，使输出图像在保留原始特征的同时又有一些随机化特性。

- **稳定化**：为了解决前向扩散过程中的不稳定性和难以控制的问题，Stable Diffusion引入了稳定化步骤。该步骤利用一个判别网络，区分生成的图像是真实图像还是随机噪声，通过使判别网络的输出概率最大化，确保生成的图像更加稳定和可控。


#### 8.2 Stable Diffusion部署
##### 8.2.1 代码获取




Stable Diffusion部署通过stable - diffusion - webui完成。stable - diffusion - webui是stable - diffusion的Web界面应用，在运行时还需要依赖一些源库，详见表8 - 1。

**表8 - 1 stable - diffusion - webui依赖库**

|依赖库|说明|
| ---- | ---- |
|stable - diffusion - stability - ai|包含从零开始训练的Stable Diffusion模型|
|generative - models|提供Stability AI发布的生成模型|
|stable - diffusion - webui - assets|提供stable - diffusion - webui的样式表和字体|
|k - diffusion|由PyTorch实现的基于扩散模型生成图像的方法|
|BLIP|用于统一视觉语言理解和生成的一种引导视觉 - 语言预训练方法|

这些库会在运行launch.py时被下载到repositories目录下，而且会按依赖关系指定相应版本，所以用户无须手动获取它们。只需要获取stable - diffusion - webui的代码，依赖的源码库就会由launch.py自行下载。
```
git clone https://github.com/AUTOMATIC1111/stable - diffusion - webui
cd stable - diffusion - webui
git checkout bef51ae
```

##### 8.2.2 Python虚拟环境准备
接下来创建合适的Python虚拟环境。stable - diffusion - webui可以运行在Python的3.10和3.11版本上。如果使用Python3.11，则在程序运行时会出现一个版本警告提示，不过这并不影响运行。
```
conda create -n stable - diffusion python=3.10 -y
conda activate stable - diffusion
```

##### 8.2.3 依赖库安装
如前所述，安装stable - diffusion - webui时，除了在运行程序前安装最基本的依赖库外，launch.py会在首次运行时下载一些依赖的源码库到repositories目录下。而这些库也有相应的依赖库要安装，为了提高安装速度，可以用以下命令设置全局pypi镜像。
```
pip config set global.index - url https://mirrors.aliyun.com/pypi/simple/
```
全局镜像的配置文件位于C:\Users\用户\AppData\Roaming\pip\pip.ini（Windows）或~/.config/pip/pip.conf（Linux）中。如果不再使用全局镜像，则可以删除配置文件。
安装依赖库命令如下。
```
pip install -r requirements.txt
```
安装完成后，校验PyTorch是否正常工作。如不正常，则可按4.2.1节提到的方法进行处理。
```
python -c "import torch; print(torch.cuda.is_available())"
```

##### 8.2.4 模型下载
按以下步骤下载模型。需要注意的是，下载完的所有文件要复制到stable - diffusion - webui/models/Stable - diffusion的根目录下。
```
# 从aliendao.cn中下载stable - diffusion - 2 - 1模型文件
wget https://aliendao.cn/model_download.py
python model_download.py -e --repo_id stabilityai/stable - diffusion - 2 - 1 \
--token YPY8KHDQ2NAHQ2SG
# 下载的文件在./dataroot/models/stabilityai/stable - diffusion - 2 - 1目录下
# 将模型文件移动到stable - diffusion - webui/models/Stable - diffusion目录下
mv./dataroot/models/stabilityai/stable - diffusion - 2 - 1/* \
models/Stable - diffusion/
```

##### 8.2.5 服务运行
按以下命令运行服务。
```
Python launch.py --no - half --listen
```
其中，“--no - half”参数的作用是禁用半精度。如果不禁用，则在一些推理卡上运行时会报错，提示为“NansException: A tensor with all NaNs was produced in UNe”。“--listen”表示服务会监听网卡的所有IP地址，这样就可以从其他计算机进行访问。如果不使用这个参数，则只能用本机通过http://127.0.0.1:7860进行访问。服务运行后台见图8 - 1。

**图8 - 1 stable - diffusion - webui后台**

（此处有一张命令行窗口截图，内容为程序运行相关信息，因文字难以完整识别，未详细提取 ）

```
### 图8 - 1 stable - diffusion - webui后台
管理员: C:\Windows\System32\cmd.exe - "D:\Anaconda3\condabin\conda.bat" activate stable - diffusion - python launch.py --no - half
This program is tested with 3.10.6 Python, but you have 3.11.8.
If you encounter an error with "RuntimeError: Couldn't install torch." message
or any other error regarding unsuccessful package (library) installation,
please downgrade (or upgrade) to the latest version of 3.10 Python
and delete current Python and `venv` folder in WebUI's directory.
You can download 3.10 Python from here: https://www.python.org/downloads/release/python - 3106/
Alternatively, use a binary release of WebUI: https://github.com/AUTOMATIC1111/stable - diffusion - webui/releases
Use --skip - python - version - check to suppress this warning.
Python 3.11.8 | packaged by Anaconda, Inc. | (main, Feb 26 2024, 21:34:05) [MSC v.1916 64 bit (AMD64)]
Version: v1.8.0
Commit hash: bef51aed032c0aaa5cfd80445bc4c0fd85b408b5
Launching Web UI with arguments: --no - half
no module 'xformers'. Proceeding without...
no module 'xformers'. Proceeding without...
No module 'xformers'. Proceeding without it.
Loading weights [ad2a33c361] from F:\temp\stable - diffusion - webui\models\Stable - diffusion\v2 - 1_768 - ema - pruned.ckpt
Running on local URL:  http://127.0.0.1:7860
To create a public link, set `share=True` in `launch()`.
Startup time: 41.5s (initialize: 2s, prepare environment: 8.2s, import torch: 14.3s, import gradio: 4.1s, setup paths: 4.2s, initialize shared: 2.5s, other imports: 2.8s, list SD models: 0.3s, load scripts: 2.7s, create ui: 0.9s, gradio launch: 1.4s).
Creating model from config: F:\temp\stable - diffusion - webui\repositories\stable - diffusion - stability - ai\configs\stable - diffusion\v2 - inference - v.yaml
Applying attention optimization: Doggettx... done.
```

#### 8.3 Stable Diffusion应用

stable - diffusion - webui正常运行后，在浏览器中通过http://server - llm - dev:7860即可访问其WebUI。



##### 8.3.1 文生图应用

在txt2img选项卡的prompt处输入提示词，单击“Generate”，就会生成与提示词相匹配的图。比如，输入“A South American footballer”（一个南美足球运动员），结果如图8 - 2所示。在实践中，用英文提示词生成的图的效果通常好于中文。

![image](https://github.com/user-attachments/assets/30e0662d-c9b4-4aa1-8d6b-bedf2179f21c)


**图8 - 2 Stable Diffusion文生图**

（此处有一张stable - diffusion - webui界面截图，包含输入框、参数设置区域和生成的足球运动员图片，因文字难以完整识别，未详细提取 ）

##### 8.3.2 图生图应用
在img2img选项卡中上传一张图片，原图如图8 - 3所示。在prompt处输入“only house”，则生成的图上会只出现房子，见图8 - 4。

![image](https://github.com/user-attachments/assets/82e46cba-01cd-45d7-b0ea-4c3091a1c167)


**图8 - 3 Stable Diffusion图生图的原图**

（此处有一张包含房屋、树木等元素的图片截图 ）

![image](https://github.com/user-attachments/assets/7b59f894-a281-4ceb-ac7e-d9496507f1c8)


**图8 - 4 Stable Diffusion图生图的目标图**

（此处有一张只包含房屋的图片截图 ） 
