### 第6章 大语言模型微调
大语言模型由大规模的参数（主要是权重）组成，如ChatGLM3-6B包含60亿个参数，GPT-3.5有超过1750亿个参数。这些参数用于表示模型学习到的语言知识和语言使用规律。在深度学习中，权重参数通常是模型中可调整的变量，其值能通过训练过程进行学习和优化。大语言模型的参数数量通常与模型的规模和复杂度相关，更多的参数意味着模型可以学习到更多、更复杂的语言特征和模式。

微调是指调整大语言模型的参数以适应特定任务的过程，这是通过在与任务相关的数据集上训练模型来完成的。其基本原理是引入新的语料，将预训练模型中的权重进行调整，具体来说，就是大语言模型由于其通用性而在一些专业领域表现不佳，通过引入新的语料数据进行二次训练，对某些层的参数进行微小的调整，以达到在这个专业领域进行更为顺畅的推理、知识更新的目的。

本章的目标是对ChatGLM3-6B、Llama-2-7b-chat-hf和Gemma-2B三个基础模型进行微调。通过阅读本章，读者可以通过P-Tuning和LoRA两种微调方法，掌握语料整理、微调操作以及微调模型应用的过程。

#### 6.1 ChatGLM微调
一般来说，在少于128GB（4×32GB）内存的较低算力推理卡环境中，进行全量微调比较困难，而可选的微调方式有P-Tuning和LoRA。本节微调的模型为ChatGLM3-6B，在P-Tuning方向上相对成熟，所以本节选用了P-Tuning v2的微调方法。P-Tuning v2微调会用到DeepSpeed ，而DeepSpeed在Windows上安装时更容易遇到问题，所以建议在Linux上进行安装。另外，DeepSpeed对CUDA和PyTorch的版本一致性的要求很高，安装PyTorch时要注意它与CUDA版本相互兼容。

##### 6.1.1 微调方法介绍
P-Tuning v2的基本原理是在预训练模型的基础上，通过添加少量的可训练参数，对模型的输出进行微调。这种方法在保持预训练模型性能的同时，提高了模型的泛化能力。P-Tuning v2的优化策略主要包括两个方面：一是采用前缀提示策略，将提示信息添加到模型的每一层中，以提高模型的输出准确性；二是采用自适应优化策略，根据模型在训练过程中的表现，动态调整微调参数的权重，以提高模型的收敛速度和性能。

##### 6.1.2 微调环境准备
ChatGLM3-6B微调的相关脚本、依赖库说明文件在https://github.com/THUDM/ChatGLM3的finetune_demo目录下。
- # 下载源码
```bash
git clone https://github.com/THUDM/ChatGLM3
cd ChatGLM3
git checkout c814a72
```
- # 建立Python3.10虚拟环境
```bash
conda create -n ChatGLM3 python=3.10 -y
conda activate ChatGLM3
```
- # 在ChatGLM3虚拟环境下安装依赖
- # 安装模型运行环境
```bash
pip install -r requirements.txt \
-i https://pypi.mirrors.ustc.edu.cn/simple \
--trusted-host=pypi.mirrors.ustc.edu.cn
```
- # 安装微调运行环境
- # 修改依赖库（单机单卡P-Tuning v2微调不依赖mpi4py）
```bash
vi finetune_demo/requirements.txt
```
- # 注释掉mpi4py，增加一行nltk命令和一行typer命令
```
#mpi4py>=3.1.5
nltk==3.8.1
typer==0.12.2
```
- # 安装微调依赖库
```bash
pip install -r finetune_demo/requirements.txt \
-i https://pypi.mirrors.ustc.edu.cn/simple \
--trusted-host=pypi.mirrors.ustc.edu.cn
```
- # 校验PyTorch环境
```bash
python -c "import torch; print(torch.cuda.is_available())"
```

##### 6.1.3 语料准备
1. **原始语料整理**
语料质量是模型训练的关键环节，训练前需要先收集语料文件，进行整理和优化，形成最原始的语料。在本次微调中，整理后的原始语料格式如下。
```
问题1？
答案1
空行
问题2？
答案2
空行
……
```
举例如如下。


**高血压患者能吃党参吗？**

高血压病人可以口服党参的。党参有降血脂，降血压的作用，可以彻底消除血液中的垃圾，从而对冠心病以及心血管疾病的患者都有一定的稳定预防工作作用，因此平时口服党参能远离三高的危害。另外党参除了益气养血，降低中枢神经作用，调整消化系统功能，健脾补肺的功能。感谢您的进行咨询，期望我的解释对你有所帮助。

**高血压该治疗什么？**

高血压患者首先要注意控制食盐摄入量，每天不超过六克，注意不要吃太油腻的食物，多吃新鲜的绿色蔬菜水果，多吃有机物，注意增强体育锻炼，增加身体素质，同时压力不要过大，精神不要紧张，效果不佳的话，可以积极配合以降压药物控制血压治疗，情绪平时保持平和，不易激动。

**老年人高血压一般如何治疗？**

高血压是老年人常见的心血管病，血管老化硬化，血压调整能力消退了，目前治疗高血压最重要的方式就是口服降压药，按时口服，不定期复检血压，把血压控制在正常范围是最理想的状态，建议定期去医院查体，平时不要抽烟喝啤酒，不要吃太咸的食物。


2. **微调语料格式要求**

对ChatGLM3模型进行微调所用的语料为多轮会话格式，具体格式如下。

```json
[
    {
        // 第一组会话
        "conversations": [
            {
                "role": "system",
                "content": "<system prompt text>"
            },
            // 第一组的第一轮会话
            {
                "role": "user",
                "content": "<user prompt text>"
            },
            {
                "role": "assistant",
                "content": "<assistant response text>"
            },
            // 第一组的第二轮会话
            {
                "role": "user",
                "content": "<user prompt text>"
            },
            {
                "role": "assistant",
                "content": "<assistant response text>"
            }
        ]
    },
    {
        // 第二组会话
    }
]
```


3. **语料格式转换**

为了将纯文本的原始语料转换成微调所需的JSON格式，以及在需要时方便将此语料转换为其他格式，本例将转换过程分成两步。第一步：原始文本文件转换为简单的JSON格式，如[{"q":"问1","a":"答1"},{"q":"问2","a":"答2"}]。第二步：将简单的JSON格式转成微调要求的语料格式。具体的转化步骤如下。

第一步，将文本文件命名为./data/original_data.txt，通过如下命令转换为./data/original_data.json。

```bash
python txt2json.py --infile./data/original_data.txt \
--outfile./data/original_data.json
```
转换过后的语料格式如下。
```json
[
    {
        "q": "高血压患者能吃党参吗？",
        "a": "高血压病人可以口服党参的。党参有降血脂，降血压的作用，可以彻底消除血液中的垃圾，从而对冠心病以及心血管疾病的患者都有一定的稳定预防工作作用，因此平时口服党参能远离三高的危害。另外党参除了益气养血，降低中枢神经作用，调整消化系统功能，健脾补肺的功能。感谢您的进行咨询，期望我的解释对你有所帮助。"
    },
    {
        "q": "高血压该治疗什么？",
        "a": "高血压患者首先要注意控制食盐摄入量，每天不超过六克，注意不要吃太油腻的食物，多吃新鲜的绿色蔬菜水果，多吃有机物，注意增强体育锻炼，增加身体素质，同时压力不要过大，精神不要紧张，效果不佳的话，可以积极配合以降压药物控制血压治疗，情绪平时保持平和，不易激动。"
    },
    {
        "q": "老年人高血压一般如何治疗？",
        "a": "高血压是老年人常见的心血管病，血管老化硬化，血压调整能力消退了，目前治疗高血压最重要的方式就是口服降压药，按时口服，不定期复检血压，把血压控制在正常范围是最理想的状态，建议定期去医院查体，平时不要抽烟喝啤酒，不要吃太咸的食物。"
    }
]
```
txt2json.py的源代码如下。
```python
import json
import argparse

def txt2json(infile, outfile):
    with open(infile, 'r', encoding='utf-8') as file:
        data = file.read()
    lines = data.split('\n')
    json_data = []
    for i in range(len(lines)):
        if (i - 2 >= 0) and ((i - 2) % 3 == 0):
            question = lines[i-2]
            answer = lines[i-1]
            json_data.append({"q": question, "a": answer})
    with open(outfile, 'w', encoding='utf-8') as file:
        json.dump(json_data, file, indent=4, ensure_ascii=False)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--infile', type=str, required=True)
    parser.add_argument('--outfile', type=str, required=True)
    args = parser.parse_args()
    txt2json(args.infile, args.outfile)
```
第二步，将简单的JSON转换成微调所需的格式。微调需要两个语料文件，一个用于训练，另一个用于验证，两者数据量占比约为70%和30%，默认文件名为train.json和dev.json。格式转换命令如下。
```bash
python convert_data.py --infile./data/original_data.json \
--trainfile./data/train.json --devfile./data/dev.json
```
convert_data.py的源代码如下。
```python
import json
import argparse

def load_data(infile):
    with open(infile, 'r', encoding='utf-8') as file:
        data = json.load(file)
    return data

def convert_data_conversations(original_data, trainfile, devfile):
    output_train = []
    dev_train = []
    train_data_len = round(len(original_data) * 0.7)
    i = 0
    for item in original_data:
        conversation = {
            "conversations": [
                {
                    "role": "user",
                    "content": item["q"]
                },
                {
                    "role": "assistant",
                    "content": item["a"]
                }
            ]
        }
        i = i + 1
        if i < train_data_len:
            output_train.append(conversation)
        else:
            dev_train.append(conversation)
    with open(trainfile, 'w', encoding='utf-8') as json_file:
        json.dump(output_train, json_file,
                  ensure_ascii=False, indent=4)
    with open(devfile, 'w', encoding='utf-8') as json_file:
        json.dump(dev_train, json_file,
                  ensure_ascii=False, indent=4)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--infile', type=str, required=True)
    parser.add_argument('--trainfile', type=str, required=True)
    parser.add_argument('--devfile', type=str, required=True)
    args = parser.parse_args()
    original_data = load_data(args.infile)
    convert_data_conversations(original_data,
                               args.trainfile, args.devfile)
```

##### 6.1.4 模型下载
本节微调的模型是ChatGLM3-6B。可以按以下步骤下载该模型。
```bash
# 从aliendao.cn下载chatglm3-6b模型文件
wget https://aliendao.cn/model_download.py
python model_download.py -e --repo_id THUDM/chatglm3-6b \
--token YP8XKHDQ2NAHQ2SG
# 下载后的文件在./dataroot/models/THUDM/chatglm3-6b目录下
```

##### 6.1.5 微调过程

使用finetune_demo/configs/ptuning_v2.yaml中定义的默认微调参数，微调需要16GB左右的GPU内存。如果推理卡内存只有16GB，则在运行过程中很可能会出现GPU内存溢出的情况。在这种情况下要适当降低模型每次载入推理卡的批量。将ptuning_v2.yaml中的per_device_train_batch_size的参数值从原来的4减少为2，这样可以省掉1GB的GPU内存。

使用以下命令开始微调，其中三个参数分别为训练语料文件和验证文件所在的路径、基础模型所在目录和微调参数配置文件。
```bash
python finetune_demo/finetune_hf.py./data \
./dataroot/models/THUDM/chatglm3-6b \
finetune_demo/configs/ptuning_v2.yaml
```

以下是一些常见的报错类型。

1. 在Ubuntu20.04上，上述微调脚本可能会报以下错误（在Ubuntu22.04上正常）。
```
ImportError: /lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.29'
```

这是因为在Ubuntu20.04上libstdc++.so.6文件的版本过旧。对此，查看系统中其他版本的同类型文件，选择其中较高版本，确认是否包含所需的GLIBCXX_3.4.29。将合适版本的文件复制到指定目录下，删除之前链接并建立新的链接。此时验证，一般程序即可成功运行（步骤示例参考https://blog.csdn.net/weixin_39379635/article/details/129159713 ）。

2. 出现以下报错，则是因为语料文件中有乱码或在JSON串中有换行符，导致无法正常装载数据集。这要重新整理语料，消除不正常的换行符。
```
Generating validation split: 0 examples [00:00,? examples/s]Killed
```
微调的过程见图6-1。当运行完默认参数所规定的3000步，可见提示如下。
```
Training completed. Do not forget to share your model on huggingface.co/models =)
```
图6-1 ChatGLM3-6B P-Tuning v2微调（图中展示了GPU相关信息及运行进程的GPU内存使用情况 ） 

![image](https://github.com/user-attachments/assets/c9b9c03d-0aab-491d-8946-76ee3593ae76)
